\chapter{Solution}
\label{chap:solution}

With a proper understanding of the Fenix Framework, this chapter
describes the solution proposed to solve the problem of relieving
programmers of the effort of programming Long Lived Transactions. It
is divided in three parts. Section~\ref{sec:arch} describes the
architecture of the proposed solution, with the rationales for each
design decision. Section~\ref{sec:impl} describes how the proposed
architecture was implemented on top of the Fenix Framework using the
JVSTM. Finally, Section~\ref{sec:validation} shows that both the
architecture and implementation fullfil all the requirements, and
attempts to measure the effort required to use the implementation.

\section{Architecture}
\label{sec:arch}

The main goal of this solution is to relieve programmers of the burden
of dealing with Long Lived Transactions, making the effort needed to
program one similar to the effort of programming a regular
transaction.

So, what does the single interaction scenario has that makes it so
easy to program? It has a single transactional context that spans the
whole operation (provided by a regular transaction, as that they have
the same lifespan). In the multiple interaction scenario the system
transaction was shorter than the business transaction, so in each step
the context was lost.

Looking at the information that is kept during the lifespan of a
regular transaction, we can identify the three major pieces:

\begin{itemize}
\item The version in which the transaction is running. This version
  number corresponds to the logical point in time in which the
  transaction occurred (i.e. its serialization point).
\item A list of all the items written throughout the transaction (and
  the respective written values). This is the critical piece, as it
  contains the updated data that will be written to the global context
  on transaction's commit.
\item A list of all elements read throughout the transaction. This
  piece of information is critical to ensure the correctness of the
  operation, as the outcome of the transaction depends on the values
  of all the read data.
\end{itemize}

These pieces are crucial to ensure the correct operation of an
STM-based transactional system. STM libraries provide them for regular
(short-lived) transactions. The solution presented below aims to
provide them for Long Lived Transactions, using the short-lived
transactions as its building blocks.

Short lived transactions keep all the necessary information in
transient transaction-local storage (typically in memory). To keep all
the necessary information available in between the steps of the Long
Lived Transaction, there needs to be a way to persist it. As the Fenix
Framework already provides mechanisms to transactionally manage and
persist information, storing the information in Domain Objects seems
like a good candidate for the solution.

\begin{figure}
  \centering
  \begin{tikzpicture}

    \begin{class}[text width=4cm]{TransactionalContext}{0,0}
      \attribute{version : int} \attribute{state : TransactionState}
    \end{class}

    \begin{class}[text width=1.6cm,minimum height=5em]{LogEntry}{4,-2}
    \end{class}

    \begin{class}[text width=3cm]{DomainObject}{8,0}
    \end{class}

    \draw [umlcd style school] (TransactionalContext) |-
    node[below]{Read Set} (LogEntry) node[near start, left]{1} node[near
    end, below]{*};

    \draw [umlcd style school] (TransactionalContext) --
    node[right]{Write Set} (LogEntry) node[near start, above]{1} node[near
    end, right]{*};

    \draw [umlcd style school] (DomainObject) -- node[left]{Object}
    (LogEntry) node[near start, above]{1} node[near end, left]{*};

    \draw [umlcd style school] (DomainObject) |- node[below]{Value}
    (LogEntry) node[near start, right]{1} node[near end, below]{1};

  \end{tikzpicture}

  \caption{Transactional Context}
  \label{fig:transactionalContext}

\end{figure}

\subsection{Data Structures}

Consider the domain model presented in
Figure~\ref{fig:transactionalContext}, as a reification of the data
necessary for a transaction to be successful. A {\bf
  TransactionalContext} is the centrepiece of the Domain, it is a
logical representation of a Long Lived Transaction, holding together
the entire state of the transaction. By being represented in the DML,
the context is kept persistently across the various steps of the
transaction, and is transactionally safe, allowing for multiple
concurrent steps of the Long Lived Transaction.

In this model, the {\bf TransactionalContext} keeps the state of the
transaction (whether it is started, committed, aborted or in
conflict) and the version marker (corresponding to the ``current''
version when the first step of the transaction executed).

A context has two associated sets of {\bf LogEntries}, one for the
Read Set and one for the Write Set. A {\bf LogEntry} represents one
read or written object throughout the transaction, by keeping a
reference to the object, as well as the value that was written (in
case the LogEntry belongs to the Write Set).

\subsection{Behaviour ?!?!}

Having the necessary data structures laid out is crucial for a proper
implementation of Long Lived Transactions, but it is just the
beginning. Whereas these structures are agnostic to the specific
backend, the backend must be able to recognise when a transaction is
executing within the context of a Long Lived Transaction.

In the Fenix Framework, transactions are bound to a specific thread,
allowing for multi-threaded applications to execute multiple
concurrent transactions in different threads. As such, to run a
transaction in the context of a Long Lived Transaction, one must first
bind the context to the current thread. This way, the backend will
check the thread-local variable for a context, to determine whether 
the transaction will be a long transaction step or
not. Listing~\ref{list:longTxBind} shows the programmer API for
binding a {\bf TransactionalContext} to a given thread. This way, the
programmer is free to run any piece of transactional context as a step
of a Long Lived Transaction.

\begin{lstlisting}[caption={Example of TransactionalContext usage},
  label={list:longTxBind}]
public void runStep(TransactionalContext context) {
  try {
    LongTransaction.setContextForThread(context);
    transactionalOperation();
  } finally {
    LongTransaction.removeContextFromThread();
  }
}

@Atomic
public void transactionalOperation() {
  (...)
}
\end{lstlisting}

Transactions occurring within the context of a Long Lived Transactions
must be aware of that fact, as this means that the semantics of domain
getters and setters are changed. 

When reading the value of a slot within a {\bf TransactionalContext},
it is the responsibility of the backend to check whether the slot is
in the write-set of transaction (so that written values can be later
read) and if it isn't, read the value of the slot in the correct
version (the version recorded in the context). Slot reads are
recorded, and stored as a {\bf LogEntry} in the Read Set.

When writing the value of a slot, the written value is stored as a
{\bf LogEntry} in the Write Set, so it can later be retrieved by read
operations and when committing the transaction.

Backends will typically intercept reads and writes to the domain, and
use their regular methods for accessing the underlying transactional
context. As such, in the end of a step, only slots belonging to the
{\bf TransactionalContext} and its {\bf LogEntries} are written to
persistent support.

\subsection{Committing}

So far we have seen what data is stored in a {\bf
  TransactionalContext} and how it is ``populated''. Now we shall look
at what happens when the Long Lived Transaction finishes, and the
context is committed.

Just like in a regular transaction, a Long Lived Transaction must be
atomic and consistent, meaning that its effects must appear to have
occurred at a single well-defined point in time. To accomplish this,
all elements of the Read Set must be validated to be in the same
version, thus ensuring that all writes were performed based on fresh
data (more details on how this is accomplished are given below). If
the validation step is successful, all the written data must be merged
into the global context, by iterating over all {\bf LogEntries} in the
Write Set, and writing the recorded value to the correct slot.

To ensure the correctness of the commit operation, both validation and
merge are performed within a regular transaction, in a
backend-specific manner (as only the backend knows how to write to an
arbitrary slot and to check if the read value is still valid). Any
conflicts on this operation, such as multiple concurrent commit
operations, or writes to validated slots will cause the commit
transaction itself to abort and restart.

Programmers can also manually roll back the Long Lived Transaction. In
this situation, all the information stored in the corresponding {\bf
  TransactionalContext} is deleted. As the Reads and Writes performed
by the transaction are stored exclusively in the context, no further
action is required.

\subsection{Integration with other APIs}



\section{Implementation}
\label{sec:impl}

The previous section described a solution to ease the development of
Long Lived Transaction. This section describes how that solution was
implemented on the Fenix Framework, using the JVSTM as the
transactional support provider.

This implementation is split into two major parts:

\begin{itemize}

\item {\bf API} contains the structural part of the Architecture (the
  domain declaration of TransactionalContexts and LogEntries), as well
  as the API available to the programmer.

\item {\bf JVSTM support} contains the actual implementation for 

\end{itemize}

The goal of this separation is twofold: to allow alternative
implementations on top of non-JVSTM backends, and to hide internal
implementation from the programmer (who should not depend on backend
code).

\subsection{Programmer API}

In the {\bf long-tx-api} module, programmers can find the available
API to work with Long Lived Transactions.

The first major component of this API is the domain. The domain is
public API, so that Long Lived Transactions can be associated with any
programmer-defined object (e.g., to a user, to a group, a process
etc). This design decision allows for a simple solution, as
cross-cutting concerns such as security and sharing are abstract, and
also gives the programmer more flexibility.

It is the programmer's responsibility to instantiate a new
TransactionalContext every time a new Long Lived Transaction is to be
started. With the context in hand, the programmer simply needs to bind
it to the thread running the step. Listing~\ref{list:longTxBind} shows
the code necessary to bind the context to a thread.

Using only this simple API, the programmer is able to easily code
features that benefit from Long Lived Transactions with little effort.

\section{Validation}
\label{sec:validation}


\subsection{Correctness}

Perhaps the greatest challenge on implementing Long Lived Transactions
vs a regular transaction is ensuring that the same correctness
guarantees are provided. This section demonstrates that the presented
solution gives the same guarantees as a regular transaction.

A regular transaction is backed by a JVSTM transaction, and as it
provides a guarantee of opacity. 

\subsection{Ease of Use}

The primary goal of this work is to ease the development of Long Lived
Transactions, and as such, it is rather important to provide a simple
and concise API.