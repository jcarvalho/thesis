\chapter{Future Work}

The solution proposed in this document, despite providing great
improvements over existing solutions, still presents several
challenges. This chapter presents a few modifications which would
greatly enhance the solution, making it both more user and developer
friendly. 

\section{Extending to other backends}

At the time this document was written, only a handful of Fenix
Framework backends were able to take advantage of the improvements for
Long Lived Transactions.

This is mostly due to the fact that the implementation requires
multi-versioning support, meaning that when a new value is written for
a given box, its previous value cannot be Garbage Collected.

For in-memory backends this doesn't pose much of a problem, as those
backends are typically used for testing and demonstrations, and as
such deal with a small data set, making it easy to fit all versions in
memory. 

Backends with persistence support on the other hand, are greatly
affected by this requirement. By storing every version persistently,
the size of the database (in whatever technology it may be: SQL,
NoSQL, text files, etc) will grow uncontrollably. Consider an
application containing a {\it User} entity, with a slot containing the
last time the user logged in. In the extreme case, the whole {\it
  User} object would be replicated each time the user logged in to the
application.

To cope with this growth rate, a Garbage Collection system would have
to be created. Assuming that Long Lived Transactions are the only
reason for multi-versioning (which in practice may not be so), such a
system could be developed.

The system would have to scan all pending Long Lived Transactions,
find the oldest one (i.e. the one with the smallest version number),
and scour through the whole database, removing entries older than such
a version. A naive approach however may not be sufficient, as stale
transactions (i.e. not accessed for a long time) would leave the old
versions sitting around for an indefinite amount of time.

An automated approach to take care of stale transactions would then be
needed. The solution for this issue is far from trivial, as a Long
Lived Transaction represents a user's Unit of Work, and as such cannot
be blindly removed. However, as old transactions are likely to be in
conflict, it should be safe to discard those, presenting the user with
a summary of the changes performed by the Long Lived
Transaction. Section \ref{sec:conflicts} briefly discusses this in
regard to conflict resolution.

However, there is a possible solution that does not require
multi-versioning. This solution would restrict the programming model,
by forcing the programmer to read every piece of data within the first
transaction step, thus ensuring that the read-set is filled within the
first step (whose version number is chosen for the transaction). The
Read Set would also have to store the read value (in a way similar to
the Write Set), ensuring that all future reads could be satisfied.

\section{Conflict Management}
\label{sec:conflicts}

Perhaps the biggest limitation of this solution is the lack of
mechanisms for conflict management. Unlike a regular transaction, a
typical Long Lived Transaction has a greater duration and size, thus
increasing both the probability of conflits and the amount of lost
work in case of a conflict.

The solution proposed so far focuses solely in strict correctness,
providing no mechanisms for conflict reduction and handling. This
section presents some ideas to solve those issues. It is divided in
two main areas: reducing conflicts altogether, and improving the way
conflicts are handled.

\subsection{Reducing Conflicts}

Consider the Course creation scenario presented in previous
chapters. Now consider that the application shows a dashboard
containing relevant information to the user. With the current
implementation of Long Lived Transactions, any change to information
shown in the dashboard would cause the Course creation to be rolled
back, even if such information had nothing to do with the creation of
the Course.

This is because rendering the Course creation page would read the
domain objects used to render the dashboard, putting them in the read
set, despite the fact that they are not directly related to the
operation the user is performing.

A possible approach would be to extend the DML to allow the programmer
to specify specific classes or slots to have their transactional
properties relaxed in Long Lived Transactions.  Slot reads for those
classes would still be registered in the TransactionalContext,
however, having slots of such classes on the Read Set would not
forcibly cause the Long Lived Transaction to abort.  Using this
feature would require special care and consideration from the
programmer, as it makes it possible to perform operations based on an
old version of a part of the data.

Another possibility is to take advantage of restartable
transactions. Restartable transactions were first introduced in the
JVSTM in \cite{cachopo2006versioned}, and was explored in more detail
in \cite{BrunoJorgeGasparFranco2013}.

Restartable transactions are programmer-defined portions of code that
are marked as being re-executable within the context of a single
transaction. When a conflict is detected due to a piece of data that
was only read inside a restartable transaction (i.e. a piece of code
marked as restartable), only that smaller transaction is restarted. If
the outcome of this transaction (which reads commit-time values) is
the same as the original execution, then it is safe to commit the
whole transaction.

Consider the naive implementation of a {\it contains} method in a {\it
  Collection} class shown in Listing \ref{list:restartable}.

\begin{lstlisting}[caption={Restartable {\it contains} method},
  label={list:restartable}]
@Restartable
public boolean contains(Object obj) {
  for(Object o : this)
    if (Objects.equals(o, obj)) return true;
  return false;
}
\end{lstlisting}

A write transaction that at some point during its execution invokes
the {\it contains} method may cause the whole collection to be read.
If a concurrent transaction adds a newly created item to the list and
commits, that will cause the original transaction to abort, as the
read value for collection is no longer the latest value.  As the
conflicting item was only read inside {\it contains}, the method is
re-executed with the latest data (in which the new element is in the
collection). If the outcome of the method is the same, the transaction
can now commit safely.

There are many challenges and limitations regarding restartable
transactions, and they are addressed in greater detail in
\cite{cachopo2006versioned} and \cite{BrunoJorgeGasparFranco2013}.

The concept of Restartable transactions can possibly be extended to
support Long Lived Transactions. In a Long Lived Transaction there are
clearly defined, individual steps which can be potentially restarted.

Recall the menu items issue presented above. Consider that between two
steps of the Long Lived Transaction, one of the menu items has its
title changed. This means that at least one step of the Long Lived
Transaction has read old data, which had no impact on the outcome of
the step.

With a few modifications to the commit algorithm and data structures,
it would be possible to restart the conflicting step(s) and check its
result against the original state. In this example, as the menu change
did not affect the operation, the outcome would be the same, and the
Long Lived Transaction could be committed.

\subsection{Handling Conflicts}

In the proposed solution, when a conflict happens the only possible
course of action is to rollback, as it is not possible to restart the
whole transaction.

If the detected conflict is not recoverable, it is up to the user to
determine whether the written data can actually be merged with the
global context. As such, handling conflicts in Long Lived Transactions
is more of a User Interaction problem than an infrastructural problem.

An interface could be devised, showing the end-user what data was
written in the transaction, and the conflicting read data, similar to
existing conflict resolution tools (such as Meld and Git's conflict
resolution mechanism).

The user could then analyse that data to determine whether the
conflicts are relevant according to the business rules, and choose to
rollback the Transaction, to merge parts of the written data or to
simply commit the operation.

Giving users so much power (as this solution could allow them to
deliberately leave the system in an inconsistent state) is
dangerous. Should the interface be poorly designed, it would be simple
for a user to perform the wrong action. It requires a great deal of
analysis, user testing and interaction testing.

\section{Expanding beyond the Fenix Framework}

Many enterprise applications use industry-standard persistence
frameworks, such as JPA, Hibernate, Spring Data, iBatis and many
others. Despite being possible to use the Fenix Framework to work on
top of such frameworks, converting existing applications to use the
Fenix Framework core API is a rather difficult and cumbersome task.

The solution proposed in this document is focused solely in the Fenix
Framework, both from a design and implementation standpoints. Long
Lived Transactions however, are a problem that is agnostic to the
technology. As such, it would be interesting to port this solution to
other, more popular, technologies.

Most of the design is actually agnostic to the Fenix Framework, and
requires features already provided by many other technologies: access
to previous versions of the domain objects and the ability to
intercept transaction boundaries as well as reads and writes.



